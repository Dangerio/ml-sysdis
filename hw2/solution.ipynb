{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone, ClassifierMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import textstat\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(59)\n",
    "X_train = pd.read_csv(\"data/my/before_feature_engineering/train.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\").iloc[:-300]\n",
    "y_train = pd.read_csv(\"data/my/before_feature_engineering/train_labels.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\").iloc[:-300]\n",
    "X_train_tr = pd.read_csv(\"data/my/after_feature_engineering/train.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\").iloc[:-300]\n",
    "groups_train = pd.read_csv(\"data/my/before_feature_engineering/train_groups.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "permutation = np.random.permutation(X_train.shape[0])\n",
    "X_train = X_train.iloc[permutation]\n",
    "X_train_tr = X_train_tr.iloc[permutation]\n",
    "y_train = y_train.iloc[permutation]\n",
    "groups_train = groups_train.iloc[permutation]\n",
    "\n",
    "X_test = pd.read_csv(\"data/my/before_feature_engineering/test.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\")\n",
    "X_test_tr = pd.read_csv(\"data/my/after_feature_engineering/test.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\")\n",
    "y_test = pd.read_csv(\"data/my/before_feature_engineering/test_labels.csv\", sep=\",\", header=0).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "y_train = y_train.fraudulent\n",
    "y_test = y_test.fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты с моделями без тюнинга гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательная функция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators):\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([estimator.predict(X) for estimator in self.estimators])\n",
    "        sum_predictions = np.sum(predictions.T, axis=1)\n",
    "        majority = (sum_predictions > (len(self.estimators) / 2)).astype(int)\n",
    "        return majority\n",
    "\n",
    "def cross_validate_and_log_metrics(model, X, y, groups, cv_class=StratifiedGroupKFold, n_splits=5):\n",
    "    cv = cv_class(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_metrics = {'f1': [], 'precision': [], 'recall': []}\n",
    "    models = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y, groups=groups)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model_new = clone(model)\n",
    "        model_new.fit(X_train, y_train)\n",
    "        models.append(model_new)\n",
    "        y_pred = model_new.predict(X_val)\n",
    "        \n",
    "        fold_metrics['f1'].append(f1_score(y_val, y_pred, zero_division=0))\n",
    "        fold_metrics['precision'].append(precision_score(y_val, y_pred, zero_division=0))\n",
    "        fold_metrics['recall'].append(recall_score(y_val, y_pred, zero_division=0))\n",
    "        \n",
    "        wandb.log({\n",
    "            'fold': fold + 1,\n",
    "            'fold_f1': fold_metrics['f1'][-1],\n",
    "            'fold_precision': fold_metrics['precision'][-1],\n",
    "            'fold_recall': fold_metrics['recall'][-1]\n",
    "        })\n",
    "    \n",
    "    mean_metrics = {\n",
    "        'mean_f1': np.mean(fold_metrics['f1']),\n",
    "        'mean_precision': np.mean(fold_metrics['precision']),\n",
    "        'mean_recall': np.mean(fold_metrics['recall'])\n",
    "    }\n",
    "    \n",
    "    wandb.log({\n",
    "        **mean_metrics,\n",
    "        'status': 'completed'\n",
    "    })\n",
    "    \n",
    "    return mean_metrics, MajorityVoteClassifier(models)\n",
    "\n",
    "def print_train_metrics(metrics):\n",
    "    for metric in metrics:\n",
    "        print(f\"Train {metric}: {metrics[metric]:.3f}\")\n",
    "\n",
    "def print_test_metrics(model, X_test, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(f\"Test F1-Score: {f1_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"Test Precision: {precision_score(y_test, y_test_pred):.3f}\")\n",
    "    print(f\"Test Recall: {recall_score(y_test, y_test_pred):.3f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайаный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве бейзлайна, мы брали логистическую регрессию, поэтому в качестве первой модели сейчас можно попробовать случайный лес, так как н позволит уловить нелинейные закономерности в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aksenovan/ml-sysdis/hw2/wandb/run-20250324_115208-xxy3aspm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dangerio/job-fake-prediction/runs/xxy3aspm' target=\"_blank\">worthy-wood-43</a></strong> to <a href='https://wandb.ai/dangerio/job-fake-prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dangerio/job-fake-prediction' target=\"_blank\">https://wandb.ai/dangerio/job-fake-prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dangerio/job-fake-prediction/runs/xxy3aspm' target=\"_blank\">https://wandb.ai/dangerio/job-fake-prediction/runs/xxy3aspm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train mean_f1: 0.190\n",
      "Train mean_precision: 0.800\n",
      "Train mean_recall: 0.125\n",
      "Test F1-Score: 0.112\n",
      "Test Precision: 1.000\n",
      "Test Recall: 0.059\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>fold</td><td>▁▃▅▆█</td></tr><tr><td>fold_f1</td><td>▁▁█▄▂</td></tr><tr><td>fold_precision</td><td>▁████</td></tr><tr><td>fold_recall</td><td>▁▁█▃▂</td></tr><tr><td>mean_f1</td><td>▁</td></tr><tr><td>mean_precision</td><td>▁</td></tr><tr><td>mean_recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>fold</td><td>5</td></tr><tr><td>fold_f1</td><td>0.10526</td></tr><tr><td>fold_precision</td><td>1</td></tr><tr><td>fold_recall</td><td>0.05556</td></tr><tr><td>mean_f1</td><td>0.19034</td></tr><tr><td>mean_precision</td><td>0.8</td></tr><tr><td>mean_recall</td><td>0.12475</td></tr><tr><td>status</td><td>completed</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-wood-43</strong> at: <a href='https://wandb.ai/dangerio/job-fake-prediction/runs/xxy3aspm' target=\"_blank\">https://wandb.ai/dangerio/job-fake-prediction/runs/xxy3aspm</a><br> View project at: <a href='https://wandb.ai/dangerio/job-fake-prediction' target=\"_blank\">https://wandb.ai/dangerio/job-fake-prediction</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250324_115208-xxy3aspm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "with wandb.init(project=\"job-fake-prediction\", \n",
    "          config={\n",
    "              \"model_type\": \"random_forest\",\n",
    "              \"validation\": \"stratified_group_kfold\",  # Changed validation type\n",
    "              \"k_folds\": n_folds\n",
    "          }):\n",
    "    metrics, averaged_model = cross_validate_and_log_metrics(model, X_train_tr, y_train, groups_train, n_splits=n_folds)\n",
    "    print_train_metrics(metrics)\n",
    "    print_test_metrics(averaged_model, X_test_tr, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что модель хуже себя показывает, чем логистическая регрессия (бейзлайн). Может быть, тюнинг гиперпараметров поможет. Хотя у этой модели есть небольшой плюс -- у нее точность 100% на трейне и тесте. Она выявляет всего 5% фрода, но зато не даёт ложно-положительных результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скрины метрик (step здесь имеет смысл очередного сплита кросс-валидации):\n",
    "![](images/random_forest/f1.png)\n",
    "![](images/random_forest/precision.png)\n",
    "![](images/random_forest/recall.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
